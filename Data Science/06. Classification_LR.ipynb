{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Put simply, classification is the task of predicting a label for a given observation. For example: you are given certain physical descriptions of an animal, and your taks is to classify them as either a dog or a cat. Here, we will classify iris flowers.\n",
    "\n",
    "As we will see later, we will use different classifiers and at the end of this notebook, we will compare them. We will define our accuracy function right now to get it out of the way. We will use a simple accuracy function that returns the ratio of the number of correctly classified observations to the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findaccuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findaccuracy(predictedvals,groundtruthvals) = sum(predictedvals.==groundtruthvals)/length(groundtruthvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the data sets that we still need\n",
    "using Pkg\n",
    "# Pkg.add(\"GLMNet\")\n",
    "# Pkg.add(\"DecisionTree\")\n",
    "# Pkg.add(\"NearestNeighbors\")\n",
    "# Pkg.add(\"Random\")\n",
    "# Pkg.add(\"DataStructures\")\n",
    "# Pkg.add(\"LIBSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLMNet\n",
    "using RDatasets\n",
    "using MLBase\n",
    "using Plots\n",
    "using DecisionTree\n",
    "using Distances\n",
    "using NearestNeighbors\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using DataStructures\n",
    "using LIBSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>150Ã—5 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">125 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">SepalLength</th><th style = \"text-align: left;\">SepalWidth</th><th style = \"text-align: left;\">PetalLength</th><th style = \"text-align: left;\">PetalWidth</th><th style = \"text-align: left;\">Species</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"CategoricalArrays.CategoricalValue{String, UInt8}\" style = \"text-align: left;\">Catâ€¦</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">5.1</td><td style = \"text-align: right;\">3.5</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">4.9</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">4.7</td><td style = \"text-align: right;\">3.2</td><td style = \"text-align: right;\">1.3</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">4.6</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">3.6</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">3.9</td><td style = \"text-align: right;\">1.7</td><td style = \"text-align: right;\">0.4</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">4.6</td><td style = \"text-align: right;\">3.4</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.3</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">3.4</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">4.4</td><td style = \"text-align: right;\">2.9</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">4.9</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">3.7</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">4.8</td><td style = \"text-align: right;\">3.4</td><td style = \"text-align: right;\">1.6</td><td style = \"text-align: right;\">0.2</td><td style = \"text-align: left;\">setosa</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">4.8</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: left;\">setosa</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">139</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.8</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">140</td><td style = \"text-align: right;\">6.9</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">2.1</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">141</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">5.6</td><td style = \"text-align: right;\">2.4</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">142</td><td style = \"text-align: right;\">6.9</td><td style = \"text-align: right;\">3.1</td><td style = \"text-align: right;\">5.1</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">143</td><td style = \"text-align: right;\">5.8</td><td style = \"text-align: right;\">2.7</td><td style = \"text-align: right;\">5.1</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">144</td><td style = \"text-align: right;\">6.8</td><td style = \"text-align: right;\">3.2</td><td style = \"text-align: right;\">5.9</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">145</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">3.3</td><td style = \"text-align: right;\">5.7</td><td style = \"text-align: right;\">2.5</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">146</td><td style = \"text-align: right;\">6.7</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">5.2</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">147</td><td style = \"text-align: right;\">6.3</td><td style = \"text-align: right;\">2.5</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">1.9</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">148</td><td style = \"text-align: right;\">6.5</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">5.2</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">149</td><td style = \"text-align: right;\">6.2</td><td style = \"text-align: right;\">3.4</td><td style = \"text-align: right;\">5.4</td><td style = \"text-align: right;\">2.3</td><td style = \"text-align: left;\">virginica</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">150</td><td style = \"text-align: right;\">5.9</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">5.1</td><td style = \"text-align: right;\">1.8</td><td style = \"text-align: left;\">virginica</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& SepalLength & SepalWidth & PetalLength & PetalWidth & Species\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Catâ€¦\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & setosa \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & setosa \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & setosa \\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & setosa \\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & setosa \\\\\n",
       "\t6 & 5.4 & 3.9 & 1.7 & 0.4 & setosa \\\\\n",
       "\t7 & 4.6 & 3.4 & 1.4 & 0.3 & setosa \\\\\n",
       "\t8 & 5.0 & 3.4 & 1.5 & 0.2 & setosa \\\\\n",
       "\t9 & 4.4 & 2.9 & 1.4 & 0.2 & setosa \\\\\n",
       "\t10 & 4.9 & 3.1 & 1.5 & 0.1 & setosa \\\\\n",
       "\t11 & 5.4 & 3.7 & 1.5 & 0.2 & setosa \\\\\n",
       "\t12 & 4.8 & 3.4 & 1.6 & 0.2 & setosa \\\\\n",
       "\t13 & 4.8 & 3.0 & 1.4 & 0.1 & setosa \\\\\n",
       "\t14 & 4.3 & 3.0 & 1.1 & 0.1 & setosa \\\\\n",
       "\t15 & 5.8 & 4.0 & 1.2 & 0.2 & setosa \\\\\n",
       "\t16 & 5.7 & 4.4 & 1.5 & 0.4 & setosa \\\\\n",
       "\t17 & 5.4 & 3.9 & 1.3 & 0.4 & setosa \\\\\n",
       "\t18 & 5.1 & 3.5 & 1.4 & 0.3 & setosa \\\\\n",
       "\t19 & 5.7 & 3.8 & 1.7 & 0.3 & setosa \\\\\n",
       "\t20 & 5.1 & 3.8 & 1.5 & 0.3 & setosa \\\\\n",
       "\t21 & 5.4 & 3.4 & 1.7 & 0.2 & setosa \\\\\n",
       "\t22 & 5.1 & 3.7 & 1.5 & 0.4 & setosa \\\\\n",
       "\t23 & 4.6 & 3.6 & 1.0 & 0.2 & setosa \\\\\n",
       "\t24 & 5.1 & 3.3 & 1.7 & 0.5 & setosa \\\\\n",
       "\t25 & 4.8 & 3.4 & 1.9 & 0.2 & setosa \\\\\n",
       "\t26 & 5.0 & 3.0 & 1.6 & 0.2 & setosa \\\\\n",
       "\t27 & 5.0 & 3.4 & 1.6 & 0.4 & setosa \\\\\n",
       "\t28 & 5.2 & 3.5 & 1.5 & 0.2 & setosa \\\\\n",
       "\t29 & 5.2 & 3.4 & 1.4 & 0.2 & setosa \\\\\n",
       "\t30 & 4.7 & 3.2 & 1.6 & 0.2 & setosa \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m150Ã—5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m SepalLength \u001b[0m\u001b[1m SepalWidth \u001b[0m\u001b[1m PetalLength \u001b[0m\u001b[1m PetalWidth \u001b[0m\u001b[1m Species   \u001b[0m\n",
       "     â”‚\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Catâ€¦      \u001b[0m\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚         5.1         3.5          1.4         0.2  setosa\n",
       "   2 â”‚         4.9         3.0          1.4         0.2  setosa\n",
       "   3 â”‚         4.7         3.2          1.3         0.2  setosa\n",
       "   4 â”‚         4.6         3.1          1.5         0.2  setosa\n",
       "   5 â”‚         5.0         3.6          1.4         0.2  setosa\n",
       "   6 â”‚         5.4         3.9          1.7         0.4  setosa\n",
       "   7 â”‚         4.6         3.4          1.4         0.3  setosa\n",
       "   8 â”‚         5.0         3.4          1.5         0.2  setosa\n",
       "   9 â”‚         4.4         2.9          1.4         0.2  setosa\n",
       "  10 â”‚         4.9         3.1          1.5         0.1  setosa\n",
       "  11 â”‚         5.4         3.7          1.5         0.2  setosa\n",
       "  â‹®  â”‚      â‹®           â‹®            â‹®           â‹®           â‹®\n",
       " 141 â”‚         6.7         3.1          5.6         2.4  virginica\n",
       " 142 â”‚         6.9         3.1          5.1         2.3  virginica\n",
       " 143 â”‚         5.8         2.7          5.1         1.9  virginica\n",
       " 144 â”‚         6.8         3.2          5.9         2.3  virginica\n",
       " 145 â”‚         6.7         3.3          5.7         2.5  virginica\n",
       " 146 â”‚         6.7         3.0          5.2         2.3  virginica\n",
       " 147 â”‚         6.3         2.5          5.0         1.9  virginica\n",
       " 148 â”‚         6.5         3.0          5.2         2.0  virginica\n",
       " 149 â”‚         6.2         3.4          5.4         2.3  virginica\n",
       " 150 â”‚         5.9         3.0          5.1         1.8  virginica\n",
       "\u001b[36m                                                   129 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = dataset(\"datasets\", \"iris\") #measurements on flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{String}:\n",
       " \"setosa\"\n",
       " \"versicolor\"\n",
       " \"virginica\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Matrix(iris[:,1:4]) #get the first four columns of the dataframe and use it as matrix (to pass for classification methods)\n",
    "irislabels = iris[:,5] #the labels\n",
    "unique(irislabels) #here are three different flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150Ã—4 Matrix{Float64}:\n",
       " 5.1  3.5  1.4  0.2\n",
       " 4.9  3.0  1.4  0.2\n",
       " 4.7  3.2  1.3  0.2\n",
       " 4.6  3.1  1.5  0.2\n",
       " 5.0  3.6  1.4  0.2\n",
       " 5.4  3.9  1.7  0.4\n",
       " 4.6  3.4  1.4  0.3\n",
       " 5.0  3.4  1.5  0.2\n",
       " 4.4  2.9  1.4  0.2\n",
       " 4.9  3.1  1.5  0.1\n",
       " 5.4  3.7  1.5  0.2\n",
       " 4.8  3.4  1.6  0.2\n",
       " 4.8  3.0  1.4  0.1\n",
       " â‹®              \n",
       " 6.0  3.0  4.8  1.8\n",
       " 6.9  3.1  5.4  2.1\n",
       " 6.7  3.1  5.6  2.4\n",
       " 6.9  3.1  5.1  2.3\n",
       " 5.8  2.7  5.1  1.9\n",
       " 6.8  3.2  5.9  2.3\n",
       " 6.7  3.3  5.7  2.5\n",
       " 6.7  3.0  5.2  2.3\n",
       " 6.3  2.5  5.0  1.9\n",
       " 6.5  3.0  5.2  2.0\n",
       " 6.2  3.4  5.4  2.3\n",
       " 5.9  3.0  5.1  1.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #our matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " â‹®\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the string flower type into numbers from 1 - 3\n",
    "irislabelsmap = labelmap(irislabels) \n",
    "y = labelencode(irislabelsmap, irislabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification, we often want to use some of the data to fit a model, and the rest of the data to validate (commonly known as `training` and `testing` data). We will get this data ready now so that we can easily use it in the rest of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perclass_splits (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each type of flower, some data will be put in training and some in testing\n",
    "function perclass_splits(y,at) \n",
    "    uids = unique(y)\n",
    "    keepids = []\n",
    "    for ui in uids\n",
    "        curids = findall(y.==ui)\n",
    "        rowids = randsubseq(curids, at)  #we use random sampling \n",
    "        push!(keepids,rowids...)\n",
    "    end\n",
    "    return keepids\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mq\u001b[22m \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mq\u001b[22m! \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mcycle T\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22mspose subset t\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22mspose! \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1ms\u001b[22mtring\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "randsubseq([rng=default_rng(),] A, p) -> Vector\n",
       "\\end{verbatim}\n",
       "Return a vector consisting of a random subsequence of the given array \\texttt{A}, where each element of \\texttt{A} is included (in order) with independent probability \\texttt{p}. (Complexity is linear in \\texttt{p*length(A)}, so this function is efficient even if \\texttt{p} is small and \\texttt{A} is large.) Technically, this process is known as \"Bernoulli sampling\" of \\texttt{A}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> randsubseq(Xoshiro(123), 1:8, 0.3)\n",
       "2-element Vector{Int64}:\n",
       " 4\n",
       " 7\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "randsubseq([rng=default_rng(),] A, p) -> Vector\n",
       "```\n",
       "\n",
       "Return a vector consisting of a random subsequence of the given array `A`, where each element of `A` is included (in order) with independent probability `p`. (Complexity is linear in `p*length(A)`, so this function is efficient even if `p` is small and `A` is large.) Technically, this process is known as \"Bernoulli sampling\" of `A`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> randsubseq(Xoshiro(123), 1:8, 0.3)\n",
       "2-element Vector{Int64}:\n",
       " 4\n",
       " 7\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  randsubseq([rng=default_rng(),] A, p) -> Vector\u001b[39m\n",
       "\n",
       "  Return a vector consisting of a random subsequence of the given array \u001b[36mA\u001b[39m,\n",
       "  where each element of \u001b[36mA\u001b[39m is included (in order) with independent probability\n",
       "  \u001b[36mp\u001b[39m. (Complexity is linear in \u001b[36mp*length(A)\u001b[39m, so this function is efficient even\n",
       "  if \u001b[36mp\u001b[39m is small and \u001b[36mA\u001b[39m is large.) Technically, this process is known as\n",
       "  \"Bernoulli sampling\" of \u001b[36mA\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  â‰¡â‰¡â‰¡â‰¡â‰¡â‰¡â‰¡â‰¡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> randsubseq(Xoshiro(123), 1:8, 0.3)\u001b[39m\n",
       "\u001b[36m  2-element Vector{Int64}:\u001b[39m\n",
       "\u001b[36m   4\u001b[39m\n",
       "\u001b[36m   7\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?randsubseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49-element Vector{Any}:\n",
       "   4\n",
       "   6\n",
       "   8\n",
       "  13\n",
       "  15\n",
       "  17\n",
       "  22\n",
       "  23\n",
       "  25\n",
       "  26\n",
       "  27\n",
       "  30\n",
       "  31\n",
       "   â‹®\n",
       " 112\n",
       " 113\n",
       " 115\n",
       " 117\n",
       " 118\n",
       " 120\n",
       " 122\n",
       " 124\n",
       " 128\n",
       " 130\n",
       " 140\n",
       " 150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainids = perclass_splits(y,0.7) #around 70% of data will be in training, about 30% in testing\n",
    "testids = setdiff(1:length(y),trainids) #so here is our testing ids and we can see we have about 50 elemts (in this case 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need one more function, and that is the function that will assign classes based on the predicted values when the predicted values are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assign_class (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_class(predictedvalue) = argmin(abs.(predictedvalue .- [1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 1: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Cross Validation\n",
       "57 models for 4 predictors in 10 folds\n",
       "Best Î» 0.006 (mean loss 0.048, std 0.008)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = glmnet(X[trainids,:], y[trainids])\n",
    "cv = glmnetcv(X[trainids,:], y[trainids]) #cross validation function which picks the best lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best lambda to predict with.\n",
    "path = glmnet(X[trainids,:], y[trainids]) \n",
    "cv = glmnetcv(X[trainids,:], y[trainids])\n",
    "mylambda = path.lambda[argmin(cv.meanloss)] #we are picking the one with the minimum mean loss\n",
    "\n",
    "            #training data    #labels   #specifying the lambda\n",
    "path = glmnet(X[trainids,:], y[trainids],lambda=[mylambda]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49Ã—1 Matrix{Float64}:\n",
       " 0.9843015599733884\n",
       " 1.0847986979494137\n",
       " 0.9621092120213237\n",
       " 0.9118606430333109\n",
       " 0.8729895502098545\n",
       " 1.0251520767396272\n",
       " 1.0697702859792304\n",
       " 0.8727560368743805\n",
       " 1.0217558332311105\n",
       " 1.00661066459319\n",
       " 1.1068742892337415\n",
       " 0.9918157659584803\n",
       " 0.9992132152758351\n",
       " â‹®\n",
       " 2.6842883449705375\n",
       " 2.8217727295333375\n",
       " 2.9717011398232174\n",
       " 2.626992596668381\n",
       " 3.0064597095788446\n",
       " 2.4168337818300296\n",
       " 2.6821709853983817\n",
       " 2.559715012805765\n",
       " 2.5375226648537\n",
       " 2.5418741406657492\n",
       " 2.799463624913536\n",
       " 2.5673459754585934"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = X[testids,:]; #testing data\n",
    "predictions_lasso = GLMNet.predict(path,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lasso = assign_class.(predictions_lasso) \n",
    "findaccuracy(predictions_lasso,y[testids]) #find the accuracy -- 95.92% of numbers that we tried to predict were correct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 2: Ridge\n",
    "We will use the same function but set alpha to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387755102040817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the best lambda to predict with.\n",
    "path = glmnet(X[trainids,:], y[trainids],alpha=0); #we set alpha =0 gives us the ridge method, default is 1 and gives us Lasso\n",
    "cv = glmnetcv(X[trainids,:], y[trainids],alpha=0)\n",
    "mylambda = path.lambda[argmin(cv.meanloss)]\n",
    "path = glmnet(X[trainids,:], y[trainids],alpha=0,lambda=[mylambda]);\n",
    "q = X[testids,:];\n",
    "predictions_ridge = GLMNet.predict(path,q)\n",
    "predictions_ridge = assign_class.(predictions_ridge)\n",
    "findaccuracy(predictions_ridge,y[testids]) #accuracy decreased!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 3: Elastic Net\n",
    "We will use the same function but set alpha to 0.5 (it's the combination of lasso and ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the best lambda to predict with.\n",
    "path = glmnet(X[trainids,:], y[trainids],alpha=0.5);\n",
    "cv = glmnetcv(X[trainids,:], y[trainids],alpha=0.5)\n",
    "mylambda = path.lambda[argmin(cv.meanloss)]\n",
    "path = glmnet(X[trainids,:], y[trainids],alpha=0.5,lambda=[mylambda]);\n",
    "q = X[testids,:];\n",
    "predictions_EN = GLMNet.predict(path,q)\n",
    "predictions_EN = assign_class.(predictions_EN)\n",
    "findaccuracy(predictions_EN,y[testids]) \n",
    "#this gives us the same as lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 4: Decision Trees\n",
    "We will use the package `DecisionTree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                2\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  [1, 2, 3]\n",
       "root:                     Decision Tree\n",
       "Leaves: 3\n",
       "Depth:  2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#different package now!\n",
    "\n",
    "#building our tree now\n",
    "model = DecisionTreeClassifier(max_depth=2) \n",
    "\n",
    "#run the fit function and use the training data and training label\n",
    "DecisionTree.fit!(model, X[trainids,:], y[trainids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387755102040817"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = X[testids,:]; #put testing data here\n",
    "predictions_DT = DecisionTree.predict(model, q) #run the prediction\n",
    "findaccuracy(predictions_DT,y[testids]) #accuracy is around 93.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 5: Random Forests\n",
    "The `RandomForestClassifier` is available through the `DecisionTree` package as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier\n",
       "n_trees:             20\n",
       "n_subfeatures:       -1\n",
       "partial_sampling:    0.7\n",
       "max_depth:           -1\n",
       "min_samples_leaf:    1\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "classes:             [1, 2, 3]\n",
       "ensemble:            Ensemble of Decision Trees\n",
       "Trees:      20\n",
       "Avg Leaves: 6.15\n",
       "Avg Depth:  4.4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are using decision tree package again\n",
    "model = RandomForestClassifier(n_trees=20)\n",
    "DecisionTree.fit!(model, X[trainids,:], y[trainids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9183673469387755"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = X[testids,:];\n",
    "predictions_RF = DecisionTree.predict(model, q)\n",
    "findaccuracy(predictions_RF,y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 6: Using a Nearest Neighbor method\n",
    "We will use the `NearestNeighbors` package here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KDTree{StaticArraysCore.SVector{4, Float64}, Euclidean, Float64, StaticArraysCore.SVector{4, Float64}}\n",
       "  Number of points: 101\n",
       "  Dimensions: 4\n",
       "  Metric: Euclidean(0.0)\n",
       "  Reordered: true"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = X[trainids,:] #use this to build the kdtree\n",
    "ytrain = y[trainids]\n",
    "kdtree = KDTree(Xtrain') #build kdtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49Ã—4 Matrix{Float64}:\n",
       " 4.6  3.1  1.5  0.2\n",
       " 5.4  3.9  1.7  0.4\n",
       " 5.0  3.4  1.5  0.2\n",
       " 4.8  3.0  1.4  0.1\n",
       " 5.8  4.0  1.2  0.2\n",
       " 5.4  3.9  1.3  0.4\n",
       " 5.1  3.7  1.5  0.4\n",
       " 4.6  3.6  1.0  0.2\n",
       " 4.8  3.4  1.9  0.2\n",
       " 5.0  3.0  1.6  0.2\n",
       " 5.0  3.4  1.6  0.4\n",
       " 4.7  3.2  1.6  0.2\n",
       " 4.8  3.1  1.6  0.2\n",
       " â‹®              \n",
       " 6.4  2.7  5.3  1.9\n",
       " 6.8  3.0  5.5  2.1\n",
       " 5.8  2.8  5.1  2.4\n",
       " 6.5  3.0  5.5  1.8\n",
       " 7.7  3.8  6.7  2.2\n",
       " 6.0  2.2  5.0  1.5\n",
       " 5.6  2.8  4.9  2.0\n",
       " 6.3  2.7  4.9  1.8\n",
       " 6.1  3.0  4.9  1.8\n",
       " 7.2  3.0  5.8  1.6\n",
       " 6.9  3.1  5.4  2.1\n",
       " 5.9  3.0  5.1  1.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = X[testids,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[3, 30, 24, 6, 21], [13, 8, 29, 31, 14], [25, 32, 1, 12, 18], [2, 7, 30, 21, 3], [11, 13, 8, 23, 20], [8, 14, 23, 20, 31], [14, 31, 12, 4, 1], [5, 3, 26, 4, 22], [9, 16, 25, 21, 7], [21, 7, 2, 30, 32]  â€¦  [95, 75, 92, 76, 99], [91, 100, 83, 86, 74], [85, 71, 73, 89, 79], [47, 54, 99, 75, 87], [95, 75, 92, 45, 54], [82, 99, 47, 87, 54], [92, 82, 45, 54, 87], [81, 84, 72, 80, 78], [98, 94, 78, 93, 80], [92, 95, 45, 54, 82]], [[0.24494897427831802, 0.26457513110645925, 0.29999999999999954, 0.2999999999999997, 0.3000000000000007], [0.33166247903553986, 0.3464101615137753, 0.3741657386773947, 0.38729833462074226, 0.38729833462074226], [0.09999999999999964, 0.14142135623730964, 0.17320508075688762, 0.1999999999999999, 0.22360679774997916], [0.1414213562373099, 0.17320508075688812, 0.19999999999999998, 0.20000000000000034, 0.264575131106459], [0.5477225575051664, 0.5567764362830022, 0.5830951894845297, 0.5916079783099616, 0.6855654600401041], [0.3464101615137753, 0.38729833462074226, 0.4582575694955838, 0.45825756949558394, 0.47958315233127247], [0.14142135623730928, 0.24494897427831772, 0.244948974278318, 0.264575131106459, 0.30000000000000016], [0.45825756949558394, 0.5099019513592785, 0.5196152422706636, 0.5656854249492381, 0.6000000000000001], [0.2999999999999998, 0.47958315233127186, 0.49999999999999983, 0.5099019513592784, 0.5196152422706631], [0.17320508075688762, 0.19999999999999993, 0.22360679774997896, 0.3000000000000002, 0.3605551275463989]  â€¦  [0.5099019513592784, 0.5196152422706629, 0.7280109889280517, 0.7549834435270756, 0.7745966692414833], [0.1414213562373093, 0.3605551275463988, 0.38729833462074165, 0.469041575982343, 0.48989794855663593], [0.4123105625617661, 0.818535277187245, 0.860232526704263, 1.0049875621120892, 1.019803902718557], [0.43588989435406705, 0.5196152422706631, 0.5830951894845299, 0.6557438524302, 0.6782329983125264], [0.31622776601683755, 0.33166247903553986, 0.5000000000000004, 0.5477225575051669, 0.6082762530298218], [0.17320508075688762, 0.24494897427831777, 0.36055512754639907, 0.3741657386773937, 0.41231056256176557], [0.14142135623730964, 0.24494897427831838, 0.2999999999999998, 0.42426406871192796, 0.4582575694955839], [0.3464101615137756, 0.5099019513592784, 0.7348469228349535, 0.7745966692414833, 0.7937253933193769], [0.360555127546399, 0.3605551275463994, 0.3741657386773939, 0.4123105625617657, 0.4123105625617659], [0.31622776601683766, 0.33166247903553997, 0.3605551275463989, 0.37416573867739383, 0.4690415759823428]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each query, it takes the five closest elements\n",
    "idxs, dists = knn(kdtree, queries', 5, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795918367346939"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ytrain[hcat(idxs...)] \n",
    "possible_labels = map(i->counter(c[:,i]),1:size(c,2)) \n",
    "predictions_NN = map(i->parse(Int,string(string(argmax(possible_labels[i])))),1:size(c,2))\n",
    "findaccuracy(predictions_NN,y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŸ£ Method 7: Support Vector Machines\n",
    "We will use the `LIBSVM` package here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " â‹®\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = X[trainids,:]\n",
    "ytrain = y[trainids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIBSVM.SVM{Int64, LIBSVM.Kernel.KERNEL}(SVC, LIBSVM.Kernel.RadialBasis, nothing, 4, 101, 3, [1, 2, 3], Int32[1, 2, 3], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Int64}, Matrix{Float64}}(34, Int32[5, 15, 14], [1, 1, 1, 1, 1, 2, 2, 2, 2, 2  â€¦  3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4.3 5.7 â€¦ 6.3 6.5; 3.0 4.4 â€¦ 2.5 3.0; 1.1 1.5 â€¦ 5.0 5.2; 0.1 0.4 â€¦ 1.9 2.0], Int32[10, 11, 16, 27, 29, 33, 35, 36, 39, 43  â€¦  82, 85, 87, 88, 91, 92, 94, 95, 99, 100], LIBSVM.SVMNode[LIBSVM.SVMNode(1, 4.3), LIBSVM.SVMNode(1, 5.7), LIBSVM.SVMNode(1, 5.1), LIBSVM.SVMNode(1, 4.5), LIBSVM.SVMNode(1, 5.1), LIBSVM.SVMNode(1, 7.0), LIBSVM.SVMNode(1, 6.5), LIBSVM.SVMNode(1, 4.9), LIBSVM.SVMNode(1, 5.0), LIBSVM.SVMNode(1, 5.6)  â€¦  LIBSVM.SVMNode(1, 6.2), LIBSVM.SVMNode(1, 7.9), LIBSVM.SVMNode(1, 6.3), LIBSVM.SVMNode(1, 6.1), LIBSVM.SVMNode(1, 6.4), LIBSVM.SVMNode(1, 6.0), LIBSVM.SVMNode(1, 6.9), LIBSVM.SVMNode(1, 5.8), LIBSVM.SVMNode(1, 6.3), LIBSVM.SVMNode(1, 6.5)]), 0.0, [0.0 0.041885424956808255; 0.3804450072984313 0.8932434518933783; â€¦ ; -0.0 -1.0; -0.0 -1.0], Float64[], Float64[], [0.05299044169797861, 0.09189685554505461, 0.06659193678630757], 3, 0.25, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svmtrain(Xtrain', ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795918367346939"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_SVM, decision_values = svmpredict(model, X[testids,:]')\n",
    "findaccuracy(predictions_SVM,y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all the results together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7Ã—2 Matrix{Any}:\n",
       " \"lasso\"  0.959184\n",
       " \"ridge\"  0.938776\n",
       " \"EN\"     0.959184\n",
       " \"DT\"     0.938776\n",
       " \"RF\"     0.918367\n",
       " \"kNN\"    0.979592\n",
       " \"SVM\"    0.979592"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracies = zeros(7)\n",
    "methods = [\"lasso\",\"ridge\",\"EN\", \"DT\", \"RF\",\"kNN\", \"SVM\"]\n",
    "ytest = y[testids]\n",
    "overall_accuracies[1] = findaccuracy(predictions_lasso,ytest)\n",
    "overall_accuracies[2] = findaccuracy(predictions_ridge,ytest)\n",
    "overall_accuracies[3] = findaccuracy(predictions_EN,ytest)\n",
    "overall_accuracies[4] = findaccuracy(predictions_DT,ytest)\n",
    "overall_accuracies[5] = findaccuracy(predictions_RF,ytest)\n",
    "overall_accuracies[6] = findaccuracy(predictions_NN,ytest)\n",
    "overall_accuracies[7] = findaccuracy(predictions_SVM,ytest)\n",
    "hcat(methods, overall_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally...\n",
    "After finishing this notebook, you should be able to:\n",
    "- [ ] split your data into training and testing data to test the effectiveness of a certain method\n",
    "- [ ] apply a simple accuracy function to test the effectiveness of a certain method\n",
    "- [ ] run multiple classification algorithms:\n",
    "    - [ ] LASSO\n",
    "    - [ ] Ridge\n",
    "    - [ ] ElasticNet\n",
    "    - [ ] Decision Tree\n",
    "    - [ ] Random Forest\n",
    "    - [ ] Nearest Neighbors\n",
    "    - [ ] Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¥³ One cool finding\n",
    "\n",
    "We used multiple methods to run classification on the `iris` dataset which is a dataset of flowers and there are three types of iris flowers in it. We split the data into training and testing and ran our methods. Here is the scoreboard:\n",
    "\n",
    "| method | accuracy score |\n",
    "|---|---|\n",
    "| lasso  |1.0|\n",
    "| ridge  |1.0|\n",
    "| EN     |1.0|\n",
    "| DT     |0.960784|\n",
    "| RF     |0.980392|\n",
    "| kNN    |1.0|\n",
    "| SVM    |1.0|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
